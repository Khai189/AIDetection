{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNJbO46IK/ck2N56Ivzv0Ss",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khai189/AIDetection/blob/main/AI_Non_AI_Images_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgz-m4ZzAELJ"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"doctorstrange420/real-and-fake-ai-generated-art-images-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n"
      ],
      "metadata": {
        "id": "aSKQ9Qm0AG3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e79b292b"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "source_path = path\n",
        "\n",
        "destination_path = '/content/kaggle_dataset'\n",
        "\n",
        "os.makedirs(destination_path, exist_ok=True)\n",
        "\n",
        "# Get all items in the source directory\n",
        "items_in_source = os.listdir(source_path)\n",
        "\n",
        "print(f\"Contents of the downloaded directory ({source_path}): {items_in_source}\")\n",
        "\n",
        "for item in items_in_source:\n",
        "    s = os.path.join(source_path, item)\n",
        "    d = os.path.join(destination_path, item)\n",
        "    print(f\"Moving {s} to {d}\")\n",
        "    shutil.move(s, d)\n",
        "\n",
        "print(f\"Dataset moved to: {destination_path}\")\n",
        "print(f\"Contents of {destination_path}: {os.listdir(destination_path)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96a2cf98"
      },
      "source": [
        "First, let's define the paths to your original data and where we want to create the new training and testing directories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61910fdb"
      },
      "source": [
        "import os\n",
        "\n",
        "# Define base paths\n",
        "data_dir = '/content/kaggle_dataset/Data'\n",
        "train_dir = '/content/train'\n",
        "test_dir = '/content/test'\n",
        "\n",
        "# Create main train and test directories\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Define subdirectories for 'Fake' and 'Real'\n",
        "classes = ['FAKE', 'REAL']\n",
        "\n",
        "for cls in classes:\n",
        "    os.makedirs(os.path.join(train_dir, cls), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_dir, cls), exist_ok=True)\n",
        "\n",
        "print(f\"Created training directories: {os.listdir(train_dir)}\")\n",
        "print(f\"Created testing directories: {os.listdir(test_dir)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd5f07ca"
      },
      "source": [
        "Now, we'll list all the image files for both 'Fake' and 'Real' categories, then use `train_test_split` to divide them. Finally, we'll move the files to their respective new training and testing directories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "188e9ecf"
      },
      "source": [
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "test_size = 0.2\n",
        "\n",
        "for cls in classes:\n",
        "    source_class_dir = os.path.join(data_dir, cls)\n",
        "\n",
        "    all_files = [os.path.join(source_class_dir, f) for f in os.listdir(source_class_dir) if os.path.isfile(os.path.join(source_class_dir, f))]\n",
        "\n",
        "    train_files, test_files = train_test_split(all_files, test_size=test_size, random_state=42)\n",
        "\n",
        "    print(f\"\\nClass: {cls}\")\n",
        "    print(f\"Total files: {len(all_files)}\")\n",
        "    print(f\"Train files: {len(train_files)}\")\n",
        "    print(f\"Test files: {len(test_files)}\")\n",
        "\n",
        "    dest_train_class_dir = os.path.join(train_dir, cls)\n",
        "    for f_path in train_files:\n",
        "        shutil.copy(f_path, dest_train_class_dir)\n",
        "\n",
        "    dest_test_class_dir = os.path.join(test_dir, cls)\n",
        "    for f_path in test_files:\n",
        "        shutil.copy(f_path, dest_test_class_dir)\n",
        "\n",
        "\n",
        "# Verify counts\n",
        "print(\"\\nVerification:\")\n",
        "for cls in classes:\n",
        "    print(f\"Train {cls} count: {len(os.listdir(os.path.join(train_dir, cls)))}\")\n",
        "    print(f\"Test {cls} count: {len(os.listdir(os.path.join(test_dir, cls)))}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n"
      ],
      "metadata": {
        "id": "IJIt-XaUBjsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "jkE_ipwQHCiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "import random\n",
        "\n",
        "train_dir_abs = '/content/train'\n",
        "test_dir_abs = '/content/test'\n",
        "\n",
        "checkpoint_dir_train = os.path.join(train_dir_abs, '.ipynb_checkpoints')\n",
        "checkpoint_dir_test = os.path.join(test_dir_abs, '.ipynb_checkpoints')\n",
        "\n",
        "if os.path.exists(checkpoint_dir_train):\n",
        "    shutil.rmtree(checkpoint_dir_train)\n",
        "    print(f\"Removed: {checkpoint_dir_train}\")\n",
        "\n",
        "if os.path.exists(checkpoint_dir_test):\n",
        "    shutil.rmtree(checkpoint_dir_test)\n",
        "    print(f\"Removed: {checkpoint_dir_test}\")\n",
        "\n",
        "train_dir = Path(train_dir_abs)\n",
        "test_dir = Path(test_dir_abs)\n",
        "\n",
        "weights = models.EfficientNet_B0_Weights.DEFAULT\n",
        "auto_transforms = weights.transforms()\n",
        "\n",
        "try:\n",
        "    train_data = ImageFolder(train_dir,\n",
        "                             transform=auto_transforms)\n",
        "\n",
        "    test_data = ImageFolder(test_dir,\n",
        "                            transform=auto_transforms)\n",
        "    print(\"ImageFolder initialization successful!\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error initializing ImageFolder: {e}\")\n",
        "    print(\"Please ensure 'train' and 'test' directories contain 'FAKE' and 'REAL' subdirectories with image files.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "h1HAnaihBty8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes"
      ],
      "metadata": {
        "id": "InUap0c7IcaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(test_data), class_names"
      ],
      "metadata": {
        "id": "l_VnmbGXFd-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "train_dataloader = DataLoader(train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              num_workers=NUM_WORKERS,\n",
        "                              shuffle=True,\n",
        "                              pin_memory=True)\n",
        "\n",
        "test_dataloader = DataLoader(test_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              num_workers=NUM_WORKERS,\n",
        "                              shuffle=False,\n",
        "                              pin_memory=True)"
      ],
      "metadata": {
        "id": "bNwIsR8hHuJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = next(iter(train_dataloader))"
      ],
      "metadata": {
        "id": "DW5Pho_wI2ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape, label.shape"
      ],
      "metadata": {
        "id": "ygmU8K7mI5LV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(image[0].cpu().permute(1, 2, 0))\n",
        "plt.title(class_names[label[0]])"
      ],
      "metadata": {
        "id": "qEll5QxUI6yU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W6A2LWvyJCyC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}